{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import LSTM, Conv1D, Flatten, Dropout, Dense, AveragePooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "top_words = 10000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pad the sequence to the same length\n",
    "max_review_length = 1600\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using embedding from Keras\n",
    "embedding_vecor_length = 300\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional model (3x conv, flatten, 2x dense)\n",
    "model.add(Conv1D(4, 5, padding='same')) #filter 16, kernel_size 5\n",
    "model.add(AveragePooling1D(2,padding='same'))\n",
    "model.add(Conv1D(8, 5, padding='same'))\n",
    "model.add(AveragePooling1D(2,padding='same'))\n",
    "model.add(Conv1D(16, 5, padding='same'))\n",
    "model.add(AveragePooling1D(2,padding='valid'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 2812s 112ms/step - loss: 0.3616 - acc: 0.8269\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 323s 13ms/step - loss: 0.2023 - acc: 0.9220\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 311s 12ms/step - loss: 0.1374 - acc: 0.9498\n",
      "Accuracy: 87.12%\n"
     ]
    }
   ],
   "source": [
    "# Log to tensorboard\n",
    "tensorBoardCallback = TensorBoard(log_dir='./logs', write_graph=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=3, callbacks=[tensorBoardCallback], batch_size=64)\n",
    "\n",
    "# Evaluation on the test set\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reference:\n",
    "#https://medium.com/@thoszymkowiak/how-to-implement-sentiment-analysis-using-word-embedding-and-convolutional-neural-networks-on-keras-163197aef623"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
